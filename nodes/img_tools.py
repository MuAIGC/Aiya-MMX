# ~/ComfyUI/custom_nodes/Aiya_mmx/nodes/img_tools.py
from __future__ import annotations
import os
import re
import json
import uuid
import time
from pathlib import Path
from typing import List, Optional

import numpy as np
import torch
from PIL import Image

import folder_paths
from ..register import register_node

# --------------------------------------------------
#  1. é€šç”¨æ‰¹é‡æ”¶å›¾å™¨  ImageBatchCollector_mmx
# --------------------------------------------------
class ImageBatchCollector_mmx:
    MAX_SLOTS = 9
    RETURN_TYPES = ("IMAGE",)
    RETURN_NAMES = ("images",)
    FUNCTION = "collect"
    CATEGORY = "utils/batch"

    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {},
            "optional": {f"image_{i}": ("IMAGE",) for i in range(1, cls.MAX_SLOTS + 1)}
        }

    def collect(self, **kwargs):
        images = [kwargs[f"image_{i}"] for i in range(1, self.MAX_SLOTS + 1) if kwargs.get(f"image_{i}") is not None]
        if not images:
            raise RuntimeError("ImageBatchCollector_mmx: æœªæ”¶åˆ°ä»»ä½•å›¾ç‰‡è¾“å…¥ï¼")
        base_h, base_w = images[0].shape[1], images[0].shape[2]
        resized = []
        for img in images:
            if img.shape[1] != base_h or img.shape[2] != base_w:
                img = torch.nn.functional.interpolate(img, size=(base_h, base_w), mode="bilinear", align_corners=False)
            resized.append(img)
        batch = torch.cat(resized, dim=0)
        return (batch,)

# --------------------------------------------------
#  2. ä¸€é”®ä¿å­˜ JPG  save2JPG_mmx
# --------------------------------------------------
class save2JPG_mmx:
    def __init__(self):
        self.output_dir = folder_paths.get_output_directory()
        self.type = "output"
        self.prefix_append = ""

    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "images": ("IMAGE",),
                "filename_prefix": ("STRING", {"default": "ComfyUI"}),
                "quality": ("INT", {"default": 95, "min": 1, "max": 100, "step": 1, "display": "slider"}),
                "optimize": ("BOOLEAN", {"default": True}),
                "progressive": ("BOOLEAN", {"default": False}),
                "save_prompt_as_txt": ("BOOLEAN", {"default": True}),
            },
            "hidden": {"prompt": "PROMPT", "extra_pnginfo": "EXTRA_PNGINFO"}
        }

    RETURN_TYPES = ("STRING", "STRING")
    RETURN_NAMES = ("prompt_text", "jpg_path")
    FUNCTION = "save_images"
    OUTPUT_NODE = True
    CATEGORY = "å“å‘€âœ¦MMX/å›¾åƒ"

    def save_images(self, images, filename_prefix="ComfyUI", quality=95, optimize=True, progressive=False,
                    save_prompt_as_txt=True, prompt=None, extra_pnginfo=None):
        from ..date_variable import replace_date_vars
        filename_prefix = replace_date_vars(filename_prefix)
        os.makedirs(self.output_dir, exist_ok=True)
        filename_prefix += self.prefix_append
        full_output_folder, filename, counter, subfolder, filename_prefix = folder_paths.get_save_image_path(
            filename_prefix, self.output_dir, images[0].shape[1], images[0].shape[0])
        prompt_text = self._extract_prompt_text(prompt)
        saved_paths, results = [], []
        for image in images:
            i = 255. * image.cpu().numpy()
            img = Image.fromarray(np.clip(i, 0, 255).astype(np.uint8))
            file = f"{filename}_{counter:05}_.jpg"
            save_path = os.path.join(full_output_folder, file)
            img.save(save_path, format='JPEG', quality=quality, optimize=optimize, progressive=progressive)
            saved_paths.append(save_path)
            if save_prompt_as_txt:
                with open(save_path.replace(".jpg", "_prompt.txt"), "w", encoding="utf-8") as f:
                    f.write(prompt_text)
            results.append({"filename": file, "subfolder": subfolder, "type": self.type})
            counter += 1
        return {"ui": {"images": results}, "result": (prompt_text, saved_paths[0] if saved_paths else "")}

    def _extract_prompt_text(self, prompt):
        if not isinstance(prompt, dict):
            return ""
        texts = []
        for node in prompt.values():
            if isinstance(node, dict) and isinstance(node.get("inputs"), dict):
                t = node["inputs"].get("prompt")
                if isinstance(t, str) and t.strip():
                    texts.append(t.strip())
        return "\n".join(texts)

# --------------------------------------------------
#  3. è·¯å¾„è¯»å›¾  LoadImageFromPath_mmx
# --------------------------------------------------
CACHE_DIR = Path(folder_paths.get_output_directory()) / "Aiya/Aiya_path"

class LoadImageFromPath_mmx:
    RETURN_TYPES = ("IMAGE",)
    RETURN_NAMES = ("image",)
    FUNCTION = "load"
    CATEGORY = "å“å‘€âœ¦MMX/å›¾åƒ"
    OUTPUT_NODE = True

    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "path": ("STRING", {"default": "", "multiline": False}),
                "cache_name": ("STRING", {"default": "default", "multiline": False}),
            },
            "optional": {"force_run": ("BOOLEAN", {"default": True})}
        }

    def load(self, path, cache_name, force_run=True):
        from ..date_variable import replace_date_vars
        path = path.strip()
        cache_name = cache_name.strip() or "default"
        path_file = CACHE_DIR / f"{cache_name}.txt"

        if path:
            path = replace_date_vars(path)
            CACHE_DIR.mkdir(parents=True, exist_ok=True)
            path_file.write_text(path, encoding="utf-8")

        if path_file.exists():
            path = path_file.read_text(encoding="utf-8").strip()
        if not path:
            print(f"[LoadImageFromPath_mmx] æ— æœ‰æ•ˆè·¯å¾„ï¼Œè¿”å›ç©ºå›¾ | cache={cache_name}")
            empty = torch.zeros((1, 1, 1, 3), dtype=torch.float32)
            return (empty,)

        path = Path(path).expanduser().resolve()
        if not path.exists():
            raise FileNotFoundError(f"LoadImageFromPath_mmx: æ–‡ä»¶ä¸å­˜åœ¨ â†’ {path}")
        img = Image.open(path).convert("RGB")
        img_np = np.array(img).astype(np.float32) / 255.0
        rgb = torch.from_numpy(img_np).unsqueeze(0)
        return (rgb,)

# --------------------------------------------------
#  4. å›¾åƒç­‰åˆ†åˆ‡å‰²  ImageSplitGrid_mmx
# --------------------------------------------------
class ImageSplitGrid_mmx:
    def __init__(self):
        pass

    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "image": ("IMAGE",),
                "width_split": ("INT", {"default": 2, "min": 1, "max": 3, "step": 1, "display": "number", "label": "å®½åº¦åˆ‡åˆ†æ•°"}),
                "height_split": ("INT", {"default": 2, "min": 1, "max": 3, "step": 1, "display": "number", "label": "é«˜åº¦åˆ‡åˆ†æ•°"}),
            }
        }

    RETURN_TYPES = tuple(["IMAGE"] * 9)
    RETURN_NAMES = tuple([f"image_{i}" for i in range(1, 10)])
    FUNCTION = "split_image"
    CATEGORY = "å“å‘€âœ¦MMX/å›¾åƒ"

    def split_image(self, image, width_split, height_split):
        if width_split < 1 or width_split > 3 or height_split < 1 or height_split > 3:
            raise ValueError("ImageSplitGrid_mmx: åˆ‡åˆ†æ•°å¿…é¡»åœ¨ 1-3 ä¹‹é—´")
        total_parts = width_split * height_split
        if total_parts > 9:
            raise ValueError(f"ImageSplitGrid_mmx: æ€»åˆ‡å‰²æ•° {total_parts} è¶…è¿‡æœ€å¤§å€¼9")

        if len(image.shape) == 4:
            if image.shape[0] != 1:
                raise ValueError("ImageSplitGrid_mmx: æš‚ä¸æ”¯æŒ batch > 1 çš„è¾“å…¥")
            image = image[0]
        height, width, channels = image.shape

        new_width = (width // width_split) * width_split
        new_height = (height // height_split) * height_split
        if new_width != width or new_height != height:
            image = image.permute(2, 0, 1).unsqueeze(0)
            image = torch.nn.functional.interpolate(image, size=(new_height, new_width), mode='bilinear', align_corners=False)
            image = image.squeeze(0).permute(1, 2, 0)

        part_w = new_width // width_split
        part_h = new_height // height_split
        parts = []
        for i in range(height_split):
            for j in range(width_split):
                sy, ey = i * part_h, (i + 1) * part_h
                sx, ex = j * part_w, (j + 1) * part_w
                parts.append(image[sy:ey, sx:ex, :].unsqueeze(0))

        result = []
        for i in range(9):
            result.append(parts[i] if i < len(parts) else
                          torch.zeros((1, part_h, part_w, channels), dtype=image.dtype, device=image.device))
        return tuple(result)

# --------------------------------------------------
#  5. æ‰¹é‡ç›®å½•å›¾ç‰‡è¯»å–å™¨  ImageFolderLoader_mmx
# --------------------------------------------------
class ImageFolderLoader_mmx:
    """
    ğŸ’• å“å‘€âœ¦MMX/æ‰¹é‡å›¾ç‰‡ç›®å½•è¯»å–å™¨
    
    ã€åŠŸèƒ½è¯´æ˜ã€‘
    â€¢ è‡ªåŠ¨æ‰«ææŒ‡å®šç›®å½•çš„æ‰€æœ‰å›¾ç‰‡ï¼ŒæŒ‰æ–‡ä»¶åæ’åºåé¡ºåºè¯»å–
    â€¢ æ”¯æŒæ‰¹é‡è¾“å‡ºï¼ˆæœ€å¤š9å¼ ï¼‰å’Œå•å¼ è¾“å‡º
    â€¢ è¯»å–è¿›åº¦è‡ªåŠ¨è®°å¿†ï¼Œæ¯æ¬¡è¿è¡Œå‰è¿›æŒ‡å®šæ­¥æ•°
    â€¢ è·¨å¹³å°æ”¯æŒï¼šWindowsè·¯å¾„(D:\img)å’ŒLinuxè·¯å¾„(/mnt/img)å‡å¯
    
    ã€æ‰¹æ¬¡è¾“å‡ºæ¨¡å¼ã€‘
    â€¢ ä¿æŒåŸå§‹æ¯”ä¾‹ï¼šä½¿ç”¨é»‘è¾¹å¡«å……(Letterbox)è€Œéæ‹‰ä¼¸ï¼Œé¿å…å›¾åƒå˜å½¢
    â€¢ ç»Ÿä¸€å°ºå¯¸ï¼šä»¥æ‰¹æ¬¡ç¬¬ä¸€å¼ å›¾ä¸ºåŸºå‡†å°ºå¯¸ï¼Œå…¶ä½™å›¾ç‰‡ç­‰æ¯”ç¼©æ”¾åå±…ä¸­å¡«å……
    """
    
    DESCRIPTION = (
        "ğŸ’• å“å‘€âœ¦MMX â€”â€” æ‰¹é‡ç›®å½•å›¾ç‰‡è¯»å–å™¨ | "
        "Letterboxæ— æ‹‰ä¼¸æ‰¹æ¬¡è¾“å‡º | æ”¯æŒWin/Linuxè·¯å¾„ | è¿›åº¦è‡ªåŠ¨è®°å¿†"
    )
    
    _path_cache: dict = {}
    _state_cache: dict = {}
    MAX_BATCH = 9
    
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "directory": ("STRING", { 
                    "default": "", 
                    "placeholder": "D:\\Photos\\input æˆ– /mnt/data/images",
                    "tooltip": "ğŸ“ å›¾ç‰‡æ‰€åœ¨ç›®å½•çš„å®Œæ•´è·¯å¾„\n"
                               "â€¢ Windowsç¤ºä¾‹: D:\\\\Photos\\\\input æˆ– D:/Photos/input\n"
                               "â€¢ Linuxç¤ºä¾‹: /mnt/data/images\n"
                               "â€¢ æ”¯æŒä½¿ç”¨ ~ è¡¨ç¤ºç”¨æˆ·ä¸»ç›®å½•"
                }),
                "batch_count": ("INT", {
                    "default": 1, 
                    "min": 1, 
                    "max": cls.MAX_BATCH, 
                    "step": 1,
                    "tooltip": "ğŸ“¦ æ¯æ¬¡è¿è¡Œè¾“å‡ºçš„å›¾ç‰‡æ•°é‡ï¼ˆ1-9å¼ ï¼‰\n"
                               "â€¢ è®¾ä¸º1ï¼šå•å¼ é¡ºåºè¯»å–æ¨¡å¼\n"
                               "â€¢ è®¾ä¸º4ï¼šæ¯æ¬¡è¾“å‡º4å¼ å›¾ç»„æˆçš„æ‰¹æ¬¡\n"
                               "æ‰¹æ¬¡å†…æ‰€æœ‰å›¾å°†ç»Ÿä¸€å°ºå¯¸ï¼Œä½†ä¿æŒåŸå§‹æ¯”ä¾‹ï¼ˆé»‘è¾¹å¡«å……ï¼‰"
                }),
                "step": ("INT", {
                    "default": 1, 
                    "min": 1, 
                    "max": 100, 
                    "step": 1,
                    "tooltip": "ğŸš¶ æ¯æ¬¡è¿è¡Œåç´¢å¼•å‰è¿›çš„æ­¥æ•°\n"
                               "â€¢ step=1ï¼šé¡ºåºè¿ç»­è¯»å–ï¼ˆ1,2,3...ï¼‰\n"
                               "â€¢ step=2ï¼šéš”ä¸€å¼ è¯»å–ï¼ˆ1,3,5...ï¼‰ï¼Œäº§ç”Ÿé‡å æˆ–è·³è·ƒæ•ˆæœ\n"
                               "æ³¨æ„ï¼šstepå¯ä»¥å¤§äºbatch_countå®ç°è·³è·ƒï¼Œä¹Ÿå¯ä»¥å°äºå®ç°é‡å "
                }),
                "reset": ("BOOLEAN", {
                    "default": False, 
                    "label_on": "ğŸ”„ é‡ç½®", 
                    "label_off": "â© ç»§ç»­",
                    "tooltip": "â€¢ å‹¾é€‰ï¼šä¸‹æ¬¡è¿è¡Œå›åˆ°ç¬¬ä¸€å¼ å›¾ï¼ˆç´¢å¼•å½’é›¶ï¼‰\n"
                               "â€¢ ä¸å‹¾é€‰ï¼šä»ä¸Šæ¬¡è®°ä½çš„ä½ç½®ç»§ç»­è¯»å–"
                }),
                "loop": ("BOOLEAN", {
                    "default": True, 
                    "label_on": "ğŸ” å¾ªç¯", 
                    "label_off": "â¹ï¸ åœæ­¢",
                    "tooltip": "â€¢ å¾ªç¯å¼€å¯ï¼šè¯»åˆ°æœ«å°¾åå›åˆ°å¼€å¤´ç»§ç»­\n"
                               "â€¢ å¾ªç¯å…³é—­ï¼šè¯»åˆ°æœ«å°¾ååœç•™åœ¨æœ€åä¸€å¼ "
                }),
            },
            "optional": {
                "file_pattern": ("STRING", {
                    "default": "*", 
                    "placeholder": "é€šé…ç¬¦å¦‚ *.jpg æˆ– frame_*.png",
                    "tooltip": "ğŸ” æ–‡ä»¶åè¿‡æ»¤é€šé…ç¬¦ï¼ˆglobæ¨¡å¼ï¼‰\n"
                               "â€¢ * æˆ– *.*ï¼šåŠ è½½æ‰€æœ‰å›¾ç‰‡ï¼ˆé»˜è®¤ï¼‰\n"
                               "â€¢ *.jpgï¼šåªåŠ è½½jpgæ ¼å¼\n"
                               "â€¢ frame_*.pngï¼šåªåŠ è½½frame_å‰ç¼€çš„png\n"
                               "â€¢ img_??.jpgï¼šåŠ è½½img_01.jpg, img_02.jpgç­‰"
                }),
            },
            "hidden": {"unique_id": "UNIQUE_ID"}
        }

    RETURN_TYPES = ("IMAGE", "IMAGE", "STRING", "INT", "INT")
    RETURN_NAMES = ("single_image", "batch", "current_file", "current_index", "total_files")
    FUNCTION = "load_images"
    CATEGORY = "å“å‘€âœ¦MMX/å›¾åƒ/æ‰¹é‡"

    @classmethod
    def IS_CHANGED(cls, **kwargs):
        """å¼ºåˆ¶æ¯æ¬¡é‡æ–°æ‰§è¡Œï¼Œé¿å…ComfyUIç¼“å­˜å¯¼è‡´ä¸è¯»å–ä¸‹ä¸€å¼ """
        return time.time()

    def collect_images_letterbox(self, tensors: List[torch.Tensor]) -> torch.Tensor:
        """
        å°†å¤šå¼ å›¾ç‰‡åˆå¹¶ä¸ºæ‰¹æ¬¡ï¼Œä½¿ç”¨Letterboxï¼ˆé»‘è¾¹å¡«å……ï¼‰ä¿æŒåŸå§‹æ¯”ä¾‹
        é¿å…ç›´æ¥æ‹‰ä¼¸å¯¼è‡´çš„å›¾åƒå˜å½¢
        """
        if not tensors:
            raise RuntimeError("ImageFolderLoader_mmx: æ²¡æœ‰å¯åˆå¹¶çš„å›¾ç‰‡")
        
        target_h, target_w = tensors[0].shape[1], tensors[0].shape[2]
        target_c = tensors[0].shape[3]
        
        processed = []
        for i, img in enumerate(tensors):
            _, h, w, c = img.shape
            
            if h == target_h and w == target_w:
                processed.append(img)
                continue
            
            scale = min(target_h / h, target_w / w)
            new_h = int(h * scale)
            new_w = int(w * scale)
            
            img_ncwh = img.permute(0, 3, 1, 2)
            img_resized = torch.nn.functional.interpolate(
                img_ncwh,
                size=(new_h, new_w), 
                mode="bilinear", 
                align_corners=False
            )
            
            letterbox = torch.zeros((1, target_c, target_h, target_w), dtype=img.dtype)
            pad_top = (target_h - new_h) // 2
            pad_left = (target_w - new_w) // 2
            letterbox[:, :, pad_top:pad_top+new_h, pad_left:pad_left+new_w] = img_resized
            img_final = letterbox.permute(0, 2, 3, 1)
            processed.append(img_final)
            
            if i > 0:
                print(f"[ImageFolderLoader_mmx] å›¾{i+1}å°ºå¯¸è°ƒæ•´: {h}x{w} -> ä¿æŒæ¯”ä¾‹ç¼©æ”¾è‡³ {new_h}x{new_w} "
                      f"å¹¶å¡«å……è‡³ {target_h}x{target_w}")
        
        batch = torch.cat(processed, dim=0)
        return batch

    def load_image_safe(self, path: Path) -> Optional[torch.Tensor]:
        """å®‰å…¨åŠ è½½å•å¼ å›¾ç‰‡å¹¶è½¬ä¸º tensor [1,H,W,C]"""
        try:
            img = Image.open(path)
            if img.mode == 'RGBA':
                background = Image.new('RGB', img.size, (0, 0, 0))
                background.paste(img, mask=img.split()[3])
                img = background
            elif img.mode != 'RGB':
                img = img.convert('RGB')
            
            img_array = np.array(img).astype(np.float32) / 255.0
            tensor = torch.from_numpy(img_array).unsqueeze(0)
            return tensor
        except Exception as e:
            print(f"[ImageFolderLoader_mmx] åŠ è½½å¤±è´¥ {path}: {e}")
            return None

    def get_image_files(self, directory: str, pattern: str) -> List[Path]:
        """è·å–ç›®å½•ä¸‹æ‰€æœ‰å›¾ç‰‡æ–‡ä»¶ï¼Œæ”¯æŒç¼“å­˜å’Œè‡ªç„¶æ’åº"""
        dir_path = Path(directory).expanduser().resolve()
        cache_key = f"{dir_path}_{pattern}"
        
        if cache_key in self._path_cache:
            return self._path_cache[cache_key]
        
        if not dir_path.exists():
            raise FileNotFoundError(f"ç›®å½•ä¸å­˜åœ¨: {dir_path}")
        if not dir_path.is_dir():
            raise NotADirectoryError(f"è·¯å¾„ä¸æ˜¯ç›®å½•: {dir_path}")
        
        valid_exts = {'.jpg', '.jpeg', '.png', '.webp', '.bmp', '.tiff', '.gif'}
        
        if pattern in ("", "*", "*.*"):
            files = [f for f in dir_path.iterdir() if f.is_file() and f.suffix.lower() in valid_exts]
        else:
            files = list(dir_path.glob(pattern))
            files = [f for f in files if f.is_file() and f.suffix.lower() in valid_exts]
        
        def natural_key(p: Path):
            return [int(s) if s.isdigit() else s.lower() for s in re.split(r'(\d+)', p.name)]
        
        files.sort(key=natural_key)
        
        if not files:
            raise RuntimeError(f"ç›®å½•ä¸­æœªæ‰¾åˆ°å›¾ç‰‡æ–‡ä»¶: {dir_path} (pattern: {pattern})")
        
        self._path_cache[cache_key] = files
        print(f"[ImageFolderLoader_mmx] ğŸ“‚ æ‰«æåˆ° {len(files)} å¼ å›¾ç‰‡: {dir_path}")
        if len(files) <= 5:
            print(f"[ImageFolderLoader_mmx]   åˆ—è¡¨: {[f.name for f in files]}")
        return files

    def load_images(self, directory: str, batch_count: int, step: int, 
                   reset: bool, loop: bool, file_pattern: str = "*", 
                   unique_id: str = None):
        if not directory.strip():
            raise ValueError("directory ä¸èƒ½ä¸ºç©º")
        
        state_key = str(unique_id) if unique_id else "default"
        image_files = self.get_image_files(directory, file_pattern)
        total = len(image_files)
        
        if reset or state_key not in self._state_cache:
            current_idx = 0
            print(f"[ImageFolderLoader_mmx] [{state_key}] ğŸ”„ é‡ç½®ç´¢å¼• | å…± {total} å¼ ")
        else:
            current_idx = self._state_cache[state_key]
            if current_idx >= total:
                current_idx = 0 if loop else total - 1
        
        if current_idx >= total:
            if loop:
                current_idx = 0
        
        selected_files = []
        indices = []
        for i in range(batch_count):
            idx = current_idx + i
            if idx >= total:
                if loop:
                    idx = idx % total
                else:
                    break
            indices.append(idx)
            selected_files.append(image_files[idx])
        
        if not selected_files:
            raise RuntimeError("æ²¡æœ‰å¯é€‰çš„å›¾ç‰‡ï¼Œè¯·æ£€æŸ¥ç´¢å¼•è®¾ç½®å’Œå¾ªç¯é€‰é¡¹")
        
        tensors = []
        for fp in selected_files:
            t = self.load_image_safe(fp)
            if t is not None:
                tensors.append(t)
        
        if not tensors:
            raise RuntimeError("æœ¬æ¬¡æ‰¹æ¬¡ä¸­æ‰€æœ‰å›¾ç‰‡åŠ è½½å¤±è´¥")
        
        single_image = tensors[0]
        
        if len(tensors) == 1:
            batch = tensors[0]
        else:
            batch = self.collect_images_letterbox(tensors)
        
        next_idx = current_idx + step
        if loop:
            next_idx = next_idx % total
        else:
            next_idx = min(next_idx, total - 1)
        
        self._state_cache[state_key] = next_idx
        current_filename = selected_files[0].name if selected_files else ""
        
        print(f"[ImageFolderLoader_mmx] [{state_key}] âœ… è¯»å– [{current_idx}/{total}] {current_filename} | "
              f"æ‰¹æ¬¡ {len(tensors)} å¼  | æ­¥è¿› +{step} -> ä¸‹ä¸€ä½ç½® {next_idx}")
        
        return (single_image, batch, current_filename, current_idx, total)

# --------------------------------------------------
#  ç»Ÿä¸€æ³¨å†Œ
# --------------------------------------------------
register_node(ImageBatchCollector_mmx, "ImageBatchCollector_mmx")
register_node(save2JPG_mmx, "save2JPG_mmx")
register_node(LoadImageFromPath_mmx, "LoadImageFromPath_mmx")
register_node(ImageSplitGrid_mmx, "ImageSplitGrid_mmx")
register_node(ImageFolderLoader_mmx, "ImageFolderLoader_mmx")
